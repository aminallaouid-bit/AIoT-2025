{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faba404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train_cnn = np.expand_dims(x_train, axis=-1)\n",
    "x_test_cnn  = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "print(\"MLP input:\", x_train.shape)\n",
    "print(\"CNN input:\", x_train_cnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3acd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "mlp.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac451bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.Sequential([\n",
    "    layers.Conv2D(16, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=2),\n",
    "    layers.Conv2D(32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d853a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH = 64\n",
    "\n",
    "hist_mlp = mlp.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hist_cnn = cnn.fit(\n",
    "    x_train_cnn, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_loss, mlp_acc = mlp.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_loss, cnn_acc = cnn.evaluate(x_test_cnn, y_test, verbose=0)\n",
    "\n",
    "print(\"MLP  -> loss:\", float(mlp_loss), \"acc:\", float(mlp_acc))\n",
    "print(\"CNN  -> loss:\", float(cnn_loss), \"acc:\", float(cnn_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d874a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_params(model):\n",
    "    return int(np.sum([np.prod(v.shape) for v in model.trainable_weights]))\n",
    "\n",
    "mlp_params = trainable_params(mlp)\n",
    "cnn_params = trainable_params(cnn)\n",
    "\n",
    "print(\"MLP trainable params:\", mlp_params)\n",
    "print(\"CNN trainable params:\", cnn_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ce6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "mlp_path = os.path.join(\"models\", \"mlp_model.h5\")\n",
    "cnn_path = os.path.join(\"models\", \"cnn_model.h5\")\n",
    "\n",
    "mlp.save(mlp_path, include_optimizer=True)\n",
    "cnn.save(cnn_path, include_optimizer=True)\n",
    "\n",
    "mlp_size_mb = os.path.getsize(mlp_path) / (1024 * 1024)\n",
    "cnn_size_mb = os.path.getsize(cnn_path) / (1024 * 1024)\n",
    "\n",
    "print(\"MLP saved size (MB):\", mlp_size_mb)\n",
    "print(\"CNN saved size (MB):\", cnn_size_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_training_memory_bytes(trainable_param_count, dtype_bytes=4, optimizer=\"adam\"):\n",
    "    param_bytes = trainable_param_count * dtype_bytes\n",
    "    if optimizer.lower() == \"adam\":\n",
    "        opt_state_bytes = 2 * param_bytes\n",
    "    else:\n",
    "        opt_state_bytes = 0\n",
    "    grad_bytes = param_bytes\n",
    "    total = param_bytes + opt_state_bytes + grad_bytes\n",
    "    return total\n",
    "\n",
    "mlp_mem_mb = estimate_training_memory_bytes(mlp_params) / (1024 * 1024)\n",
    "cnn_mem_mb = estimate_training_memory_bytes(cnn_params) / (1024 * 1024)\n",
    "\n",
    "print(\"Estimated training memory (MB) - MLP:\", mlp_mem_mb)\n",
    "print(\"Estimated training memory (MB) - CNN:\", cnn_mem_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba332262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_flops(model, input_shape):\n",
    "    try:\n",
    "        concrete = tf.function(model).get_concrete_function(\n",
    "            tf.TensorSpec([1] + list(input_shape), model.inputs[0].dtype)\n",
    "        )\n",
    "        frozen_func, graph_def = tf.python.framework.convert_to_constants.convert_variables_to_constants_v2_as_graph(concrete)\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.graph_util.import_graph_def(graph_def, name=\"\")\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return int(flops.total_float_ops) if flops is not None else None\n",
    "    except Exception as e:\n",
    "        print(\"FLOPs profiling failed:\", e)\n",
    "        return None\n",
    "\n",
    "mlp_flops_inf = infer_flops(mlp, (28, 28))\n",
    "cnn_flops_inf = infer_flops(cnn, (28, 28, 1))\n",
    "\n",
    "mlp_flops_train = (2 * mlp_flops_inf) if mlp_flops_inf is not None else None\n",
    "cnn_flops_train = (2 * cnn_flops_inf) if cnn_flops_inf is not None else None\n",
    "\n",
    "print(\"MLP FLOPs inference:\", mlp_flops_inf)\n",
    "print(\"MLP FLOPs training :\", mlp_flops_train)\n",
    "print(\"CNN FLOPs inference:\", cnn_flops_inf)\n",
    "print(\"CNN FLOPs training :\", cnn_flops_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8eeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"MLP\",\n",
    "        \"Test Accuracy\": float(mlp_acc),\n",
    "        \"Test Loss\": float(mlp_loss),\n",
    "        \"Trainable Parameters\": int(mlp_params),\n",
    "        \"Saved Model Size (MB)\": float(mlp_size_mb),\n",
    "        \"FLOPs (Training)\": mlp_flops_train,\n",
    "        \"FLOPs (Inference)\": mlp_flops_inf,\n",
    "        \"Training Memory (MB)\": float(mlp_mem_mb),\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"CNN\",\n",
    "        \"Test Accuracy\": float(cnn_acc),\n",
    "        \"Test Loss\": float(cnn_loss),\n",
    "        \"Trainable Parameters\": int(cnn_params),\n",
    "        \"Saved Model Size (MB)\": float(cnn_size_mb),\n",
    "        \"FLOPs (Training)\": cnn_flops_train,\n",
    "        \"FLOPs (Inference)\": cnn_flops_inf,\n",
    "        \"Training Memory (MB)\": float(cnn_mem_mb),\n",
    "    },\n",
    "])\n",
    "\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
